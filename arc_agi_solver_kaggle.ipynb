{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- SPDX-License-Identifier: MPL-2.0 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARC AGI Solver - Kaggle Submission\n",
    "This notebook adapts the ARC AGI Solver for the Kaggle environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up paths\n",
    "KAGGLE_INPUT = \"/kaggle/input\"\n",
    "KAGGLE_WORKING = \"/kaggle/working\"\n",
    "REPO_DIR = os.path.join(KAGGLE_WORKING, \"arc-agi-solver\")\n",
    "\n",
    "# Clone the repository\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/lexsightllc/arc-agi-solver.git {REPO_DIR}\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -r {os.path.join(REPO_DIR, 'requirements.txt')}\n",
    "!pip install -e {REPO_DIR}\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.append(REPO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Paths for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Update config paths\n",
    "config_path = os.path.join(REPO_DIR, \"config\", \"config.yaml\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update paths for Kaggle\n",
    "config['data_dir'] = os.path.join(KAGGLE_INPUT, \"arc-prize-2025\")\n",
    "config['private_data_dir'] = os.path.join(KAGGLE_INPUT, \"arc-agi-solver\")\n",
    "config['log_dir'] = os.path.join(KAGGLE_WORKING, \"logs\")\n",
    "config['output_dir'] = os.path.join(KAGGLE_WORKING, \"outputs\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(config['log_dir'], exist_ok=True)\n",
    "os.makedirs(config['output_dir'], exist_ok=True)\n",
    "\n",
    "# Save updated config\n",
    "with open(os.path.join(KAGGLE_WORKING, \"config_kaggle.yaml\"), 'w') as f:\n",
    "    yaml.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.prepare_data import load_arc_dataset, split_dataset\n",
    "\n",
    "# Load competition data\n",
    "train_data = load_arc_dataset(os.path.join(KAGGLE_INPUT, \"arc-prize-2025\", \"training\"))\n",
    "test_data = load_arc_dataset(os.path.join(KAGGLE_INPUT, \"arc-prize-2025\", \"test\"))\n",
    "\n",
    "# Load private dataset if available\n",
    "private_data = {}\n",
    "private_data_path = os.path.join(KAGGLE_INPUT, \"arc-agi-solver\", \"data\")\n",
    "if os.path.exists(private_data_path):\n",
    "    private_data = load_arc_dataset(private_data_path)\n",
    "\n",
    "# Combine datasets if needed\n",
    "if private_data:\n",
    "    train_data.update(private_data)\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training examples\")\n",
    "print(f\"Loaded {len(test_data)} test examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.learning.trainer import Trainer\n",
    "from src.learning.dataset import ARCDataset\n",
    "from src.learning.models import PolicyNetwork\n",
    "import torch\n",
    "\n",
    "# Initialize model and trainer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PolicyNetwork().to(device)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_data=train_data,\n",
    "    val_data=test_data,  # In practice, use a proper validation split\n",
    "    config=config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.predictor import Predictor\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = Predictor(model=model, device=device)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = {}\n",
    "for task_id, task_data in test_data.items():\n",
    "    try:\n",
    "        prediction = predictor.predict(task_data)\n",
    "        predictions[task_id] = prediction\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing task {task_id}: {str(e)}\")\n",
    "        predictions[task_id] = None\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'output_id': [f\"{task_id}_output\" for task_id in predictions.keys()],\n",
    "    'output': list(predictions.values())\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = os.path.join(KAGGLE_WORKING, \"submission.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission saved to {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = os.path.join(KAGGLE_WORKING, \"model.pth\")\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save logs and outputs\n",
    "!cp -r {os.path.join(REPO_DIR, 'logs')} {KAGGLE_WORKING}\n",
    "!cp -r {os.path.join(REPO_DIR, 'outputs')} {KAGGLE_WORKING}\n",
    "\n",
    "print(\"Notebook execution completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}